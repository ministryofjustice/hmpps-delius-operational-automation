- name: Setup Oracle database parameters, autotasks and post tasks
  hosts: "{{ duplicate_target }}"
  gather_facts: no
  become: yes
  become_user: oracle

  tasks:
    # This is used to send warnings about issues encountered during the duplicate
    # which require fixing but are not serious enough to abort the job.
    - name: Set Variable For OEM Secrets
      set_fact:
        oem_secretsmanager_passwords:
          emrep:
            account_name: "hmpps-oem-{{ aws_environment }}"
            assume_role_name: "{{ oem_secret_role }}"
            secret: "/oracle/database/EMREP/shared-passwords"
            users:
              - slack_token:

    - name: Get Slack Token
      include_tasks: "{{ playbook_dir }}/../../common/tasks/get_facts.yml"

    # In most cases we are duplicating an ASM-based database to ASM.
    # However, if we duplicate from a file system based database (non-ASM)
    # then the resultant files will be in ASM and referenced by a number
    # of aliases.   It makes things easier and more standard if we
    # reference these files directly instead of via aliases.
    # The following script handles this change.
    # It will find nothing to change on databases duplicated from ASM.
    - name: Remove Aliases Created by non-ASM to ASM Duplication
      script: remove_asm_aliases.sh
      register: remove_asm_aliases
      changed_when: remove_asm_aliases.stdout is search('.*ALTER.*')
      vars:
        ansible_aws_ssm_timeout: 3600

    - name: Check if Data Patch is Installed
      script: get_datapatch_applied.sh
      changed_when: false
      register: get_datapatch_applied
      tags: datapatch

    - name: Run Datapatch
      tags: datapatch
      when: get_datapatch_applied.stdout is search('.*Datapatch is not installed.*')
      block:

        # In case we have duplicated from a lower RU database, run datapatch to update
        # (Will take no action if no release update patches required)
        # Occassionally we might encounter ORA-54 if run with database open, so use upgrade mode
        - name: Shutdown Primary Database
          include_tasks: shutdown_database.yml

        - name: Startup Primary Database in Upgrade Mode for Datapatch
          script: startup_database_upgrade.sh

        # Datapatch can occassionally fail when previous OJVM patch is rolled back.   However the replacement patch is
        # then normally installed successfully.   Fix from Oracle if this happens is to simply re-run datapatch so
        # we allow up to 3 retries to complete without errors.
        - name: Run Datapatch on Primary
          shell: |
            . ~/.bash_profile
            cd ${ORACLE_HOME}/OPatch
            ./datapatch -verbose
          register: datapatch
          retries: 3
          delay: 1
          until: datapatch.rc == 0
          async: 1800
          poll: 60
          failed_when: datapatch.rc !=0 or datapatch.stdout is search('command failed with errors')

        - name: Show Datapatch Output
          debug: var=datapatch.stdout_lines

        - name: Shutdown Primary Database
          include_tasks: shutdown_database.yml

        - name: Startup Database for Normal Use
          include_tasks: startup_database.yml

    - name: Setup Environment Specific Oracle Parameters
      import_role:
        name: "{{ playbook_dir }}/../oracle_parameters/set_oracle_parameters"
      vars:
        target_host: "{{ duplicate_target }}"

    - name: Setup Environment Specific Oracle Auto Tasks
      import_role:
        name: "{{ playbook_dir }}/../oracle_autotasks/configure_oracle_autotasks"
      vars:
        target_host: "{{ duplicate_target }}"
      tags: auto_tasks

    # Although the new database would be registered automatically during the next backup, we do the registration
    # now in advance as this allows us to backup any archive logs which may be required to support a restore point
    # before the first backup has been taken.
    - name: Register Database with RMAN Catalog
      include_tasks: register_with_rman.yml

    - block:
        # Ensure that no sequences in duplicated environments overlap IDs
        # with production IDs by incrementing these to a higher range
        - name: Bump sequences
          script: bump_sequences.sh
          register: bump_sequences
          changed_when: bump_sequences.stdout is search ('.*Bumped.*')

        # - name: Update objects
        #   include_tasks: ../delius_objects/playbook.yml

        - name: Create and restore delius users
          include_tasks: ../delius_users/playbook.yml
          vars:
            action_type: "all"
          tags: delius_users

        - name: Create Delius gdpr_pool database user
          include_tasks: ../delius_gdpr/playbook.yml

        - name: Deploy CFO Daily Extract
          include_tasks: ../cfo_extract/playbook.yml

        - name: Setup Alfresco Wallet and ACL
          include_role:
            name: "{{ playbook_dir }}/../alfresco_wallet/alfresco_wallet"
          vars:
            certificate_dict: {}

        # If a problem has occurred refreshing Alfresco it may not be up and running at this point.
        # Send a warning by Slack but do not abort the duplicate.
        - name: Notify on Alfresco Server Error
          community.general.slack:
            token: "{{ slack_token }}"
            msg: "Alfresco configuration failed on {{ inventory_hostname }}.  The response from the Alfresco server was {{ check_alfresco_url.msg | default('unknown') }}.  Ignoring errors and continuing with duplication tasks."
            channel: "#delius-aws-oracle-dev-alerts"
            username: "Delius Database Duplicate on {{ inventory_hostname }}"
            icon_emoji: ":sign-warning:"
          delegate_to: localhost
          become: no
          ignore_errors: true
          when:
            - alfresco_host != 'NOT CONFIGURED'
            - check_alfresco_url.failed

      when: duplicate_target | regex_search('.*_delius_primarydb')

# # We ignore any errors during the database uplift as these can be resolved afterwards
# # and this is preferable to leaving the duplicate only partially completed.
# - name: 'Uplift database'
#   import_playbook: ../../../delius-core/playbooks/deploy-application.yml
#   when: duplicate_target | regex_replace('(^.*)_.*$','\\1') == 'delius'
#   vars:
#      deploy_rbac: false
#      ldap_hosts: 'none'
#      db_ha_counts: {'delius': {'high_availability_count': 0}, 'mis': {'high_availability_count': 0}}
#      deploy_application: false
#      deploy_database: true
#      create_restore_point: false
#      ignore_pdm_uplift_errors: true
#   tags: deploy_application

# - name: Notify If Uplift Error
#   import_playbook: notify-on-uplift-error.yml
#   when: duplicate_target | regex_replace('(^.*)_.*$','\\1') == 'delius'
#   tags: deploy_application

# Re-run bumping of sequence numbers to capture any new sequences which may have
# been added by the database uplift
- name: Re-bump sequences
  hosts: "{{ duplicate_target }}"
  gather_facts: no
  become: yes
  become_user: oracle

  tasks:
    - name: Bump sequences
      script: bump_sequences.sh
      when: duplicate_target | regex_search('.*_delius_primarydb')
      register: re_bump_sequences
      changed_when: re_bump_sequences.stdout is search ('.*Bumped.*')

# The database uplift should already have unblocked the listener but we do it again
# just in case that step had failed
- name: "Unblock listener"
  import_playbook: unblock_listener.yml
  vars:
    target_host: "{{ duplicate_target }}"

- name: "Setup Oracle Statspack"
  import_playbook: ../oracle_statspack/playbook.yml
  vars:
    target_hosts: "{{ duplicate_target }}"

- name: Create mis database links if required
  hosts: "{{ duplicate_target }}"
  gather_facts: no
  become: yes
  become_user: oracle

  tasks:
    - name: create database links
      include_tasks: ../mis_database_links/playbook.yml
      when: duplicate_target | regex_search('.*_mis_primarydb')

- name: Import dfi schemas only for STGMIS
  import_playbook: dfi-schemas.yml
  vars:
    action: "import"
  when:
    - duplicate_target | regex_search('.*_mis_primarydb')
    - database_primary_sid | regex_search('STGMIS.*$')

- name: Copy delius datasets required
  import_playbook: delius-datasets.yml
  vars:
    action: "copy"
  when:
    - duplicate_target | regex_search('.*_delius_primarydb')


- name: Create and Restore MIS Users
  hosts: "{{ duplicate_target }}"
  gather_facts: no
  become: yes
  become_user: oracle

  tasks:

    - name: Create and restore MIS users
      include_tasks: ../delius_users/playbook.yml
      vars:
        action_type: "all"
        application_type: "mis"


- name: Update ND Parameter values
  import_playbook: update-nd-parameters.yml
  when: duplicate_target | regex_search('.*_delius_primarydb')
# - name: Re-enable probation integration updates
#   hosts: '{{ duplicate_target }}'
#   gather_facts: no
#   become: yes
#   become_user: oracle

#   tasks:
#     - name: Trigger GitHub Actions workflow to switch probation integration services back to read-write mode
#       shell: |
#         environment_name=$(. ~/.bash_profile && . /etc/environment && echo $HMPPS_ENVIRONMENT)
#         if [ "$environment_name" == 'delius-pre-prod' ]; then
#           token=$(aws ssm get-parameter --name '/delius-pre-prod/delius/probation-integration/github/token' --region {{ region }} --output text --with-decryption --query Parameter.Value)
#           curl -fsSL -X POST -H 'Accept: application/vnd.github+json' -H "Authorization: token $token" \
#             --data '{"ref": "main", "inputs": {"action": "disable", "environment": "preprod"}}' \
#             https://api.github.com/repos/ministryofjustice/hmpps-probation-integration-services/actions/workflows/readonly.yml/dispatches
#         fi
#       when: duplicate_target | regex_replace('(^.*)_.*$','\\1') == 'delius'
