---
- name: Set Backup Bucket
  set_fact:
    statistics_backup_bucket: "{{ environment_name }}-oracle-db-statistics-backup-data"

- name: Get Locatio n of Statistics Dump File
  script: get_dump_location.sh
  register: get_dump_location

- name: Check Path Defined
  fail:
    msg: "Could not find path to dump file."
  when: get_dump_location | length < 2

- name: Define Schemas for Statistics Gathering
  set_fact:
    target_schemas:
      - DELIUS_APP_SCHEMA

- name: Generate Quoted List of Schemas
  set_fact:
    target_schemas_list: >-
      {{ ( target_schemas_list | default('') ) + ( '' if (schema_index == 0) else ',' ) + ( item | regex_replace("^(.*)$","'\1'") ) }}
  loop: "{{ target_schemas }}"
  loop_control:
    index_var: schema_index

- name: Find Which of these Schemas Contain Tables or Indexes
  script: get_populated_schemas.sh "{{ target_schemas_list }}"
  register: get_populated_schemas
  changed_when: false

- name: Define Schemas for Statistics Gathering
  set_fact:
    all_schemas: "{{ get_populated_schemas.stdout_lines | reject('match', '^$') }}"

- name: Set Global Statistics Preferences
  script: set_global_prefs.sh
  register: set_global_prefs
  changed_when: set_global_prefs.stdout is search('.*Changed.*')

- name: Create Statistics Backup Table
  script: create_stats_backup_table.sh
  register: get_stats_backup_table
  changed_when: not get_stats_backup_table.stdout is search('.*table already exists.*')
  tags: backup

# Use Timestamp as Part of Default Statistics Backup Identifier
- name: Get Local Time
  setup:
    filter: ansible_date_time
  run_once: yes
  delegate_to: localhost
  become: no

- name: Default Statistics Identifier
  set_fact:
    statid: "{{ 'DELIUS_STATS_' + ansible_date_time.iso8601_basic_short if ((not statistics_identifier is defined) or (statistics_identifier == '')) else ( statistics_identifier | upper ) }}"

# If we are importing statistics from a remote database (import_source_environment is not "None")
# then we want to take a backup of the current local statistics before doing so but do not use the
# same StatId as this will lead to conflicting row - instead add a prefix to the StatId

- name: Define Statistics Identifier for Local Backup Prior to Import
  set_fact:
    statid_for_backup: "{{ statid if (import_source_environment == 'None' or (import_source_environment != 'None' and export_to_s3 | bool ))  else ('BKP_' + ansible_date_time.iso8601_basic_short + '_PRE_' + (import_source_environment | replace('-','_') | upper ))  |  truncate(30,true,'') }}"

- name: Define Statistics Identifier for Local Backup Prior to Gathering
  set_fact:
    statid_for_backup: "{{ 'BKP_' + ansible_date_time.iso8601_basic_short + '_PRE_GATHERING_STATS' if (gather_new_statistics | default(false) | bool) else statid_for_backup }}"

# We always backup the schema statistics before importing or gathering new statistics in case we need to revert
- name: Backup Existing Schema Statistics using StatId {{ statid_for_backup }}
  script: backup_schema_statistics.sh "{{ schema }}" "{{ statid_for_backup }}"
  register: backup_schema_statistics
  changed_when: backup_schema_statistics.stdout is search('.*Backed up.*')
  loop: "{{ all_schemas | upper }}"
  loop_control:
    loop_var: schema
  tags: backup

- name: Export Backup Statistics to S3
  when: export_to_s3 | bool
  block:

    - name: Export Backup Statistics
      shell: |
        . ~/.bash_profile
        expdp \"/ as sysdba\" dumpfile=statistics_backup.dmp logfile=statistics_backup.log reuse_dumpfiles=y directory=DATA_PUMP_DIR tables=DELIUS_USER_SUPPORT.STATISTICS_BACKUP query=\"WHERE statid=\'{{ statid }}\'\"
      register: export_backup_statistics
      tags: backup

    - name: Copy Backup Statistics Dump File to S3
      amazon.aws.s3_object:
        bucket: "{{ statistics_backup_bucket }}"
        object: "/datapump/{{ statid }}.{{ item }}"
        src: "{{ get_dump_location.stdout | trim }}/statistics_backup.{{ item }}"
        mode: put
      loop: ["dmp", "log"]

- name: Import Statistics from Other Environment
  include_tasks: import_remote_stats.yml
  vars:
    remote_environment_name: "{{ import_source_environment }}"
    remote_statistics_identifier: "{{ statid | regex_replace('^(DELIUS_STATS)', import_source_environment | replace('-','_') | upper)) }}"
  when: (import_source_environment != 'None') and (not export_to_s3 | bool)

- name: Gather New Statistics
  when: gather_new_statistics | default(false) | bool
  block:
    - name: Lock Statistics on Tables Changed Recently
      script: lock_changed_table_stats.sh "{{ schema }}" 28
      register: lock_changed_table_stats
      changed_when: not lock_changed_table_stats.stdout is search('.*Statistics Locked on 0 tables.*')
      loop: "{{ all_schemas | upper }}"
      loop_control:
        loop_var: schema
      tags: statistics

    - name: Lock Statistics on Tables with No Segments
      script: lock_no_segment_stats.sh "{{ schema }}"
      register: lock_no_segment_stats
      changed_when: not lock_no_segment_stats.stdout is search('.*Statistics Locked on 0 tables.*')
      loop: "{{ all_schemas | upper }}"
      loop_control:
        loop_var: schema
      tags: statistics

    - name: Lock Statistics on Z_ Tables
      script: lock_z__stats.sh "{{ schema }}"
      register: lock_z__stats
      changed_when: not lock_z__stats.stdout is search('.*Statistics Locked on 0 tables.*')
      loop: "{{ all_schemas | upper }}"
      loop_control:
        loop_var: schema
      tags: statistics

    - name: Create Statistics Directory
      file:
        path: /home/oracle/admin/statistics
        owner: oracle
        group: oinstall
        mode: 0755
        state: directory

    - name: Install Statistics script
      copy:
        src: gather_statistics.sh
        dest: /home/oracle/admin/statistics/gather_statistics.sh
        owner: oracle
        group: oinstall
        mode: 0544

    # The quotes in the JSON inputs can get messed up by unwanted shell interpretation.
    # To avoid this we send the JSON as an encoded string to be decoded by the shell script.
    - name: Enable Repository Dispatch Event if supplied
      set_fact:
        repository_dispatch_flag: "-r {{ repository_dispatch }} -j {{ json_inputs | b64encode }}"
      when:
        - repository_dispatch is defined
        - json_inputs is defined
    
    - name: Single Varaible Containing Schemas And Table Names To Remove Transient Table Statistics Locks
      set_fact:
        database_locked_statistics: "-t {{ database_locked_statistics | default([]) | to_nice_json | b64encode }}"
      when: database_locked_statistics

    - name: Create Statistics Command
      set_fact:
        statistics_command: "/home/oracle/admin/statistics/gather_statistics.sh -s {{ all_schemas | join(',') }} -p {{ parallelism }} {{ repository_dispatch_flag | default() }} {{ database_locked_statistics | default() }}"

    - name: Show Statistics Command
      debug:
        msg: "About to run: {{ statistics_command }}"

    - name: Running Statistics Script In Background
      shell: "{{ statistics_command }}"
      async: "{{ allowable_duration|default(28800) }}"
      poll: 0
      register: statistics_cmd_output